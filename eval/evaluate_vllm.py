"""
æ³•å¾‹åˆ¤å†³é¢„æµ‹ï¼ˆLJPï¼‰æµ‹è¯„è„šæœ¬ - vLLMç‰ˆæœ¬
ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨LawShiftæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œä½¿ç”¨vLLMåŠ é€Ÿæ¨ç†
"""

import json
import re
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Any
from datetime import datetime
from vllm import LLM, SamplingParams
from tqdm import tqdm

try:
    from ..prompt_template import SYSTEM_PROMPT, format_user_prompt, format_articles
except ImportError:
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from prompt_template import SYSTEM_PROMPT, format_user_prompt, format_articles


class LawShiftEvaluatorVLLM:

    def __init__(self, model_path: str, tensor_parallel_size: int = 1, gpu_memory_utilization: float = 0.9):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨ï¼ˆä½¿ç”¨vLLMï¼‰

        Args:
            model_path: æ¨¡å‹è·¯å¾„
            tensor_parallel_size: å¼ é‡å¹¶è¡Œæ•°ï¼ˆå¤šGPUæ—¶ä½¿ç”¨ï¼‰
            gpu_memory_utilization: GPUæ˜¾å­˜åˆ©ç”¨ç‡ (0.0-1.0)
        """
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹ (vLLM): {model_path}")
        self.model_path = model_path

        # åŠ è½½ label æ˜ å°„
        self.label_mapping = {}
        label_path = Path(__file__).parent.parent / "label.json"

        if label_path.exists():
            with open(label_path, 'r', encoding='utf-8') as f:
                labels = json.load(f)
                for item in labels:
                    self.label_mapping[item['name']] = item['label']
            print(f"å·²åŠ è½½ {len(self.label_mapping)} ä¸ªæ ‡ç­¾æ˜ å°„")
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ° label.json æ–‡ä»¶: {label_path}")

        # ä½¿ç”¨ vLLM åŠ è½½æ¨¡å‹
        print("åŠ è½½æ¨¡å‹ä¸­...")
        self.llm = LLM(
            model=model_path,
            tensor_parallel_size=tensor_parallel_size,
            gpu_memory_utilization=gpu_memory_utilization,
            trust_remote_code=True,
        )

        # è·å– tokenizerï¼ˆç”¨äºæ„å»º promptï¼‰
        self.tokenizer = self.llm.get_tokenizer()

        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
        print(f"å¼ é‡å¹¶è¡Œå¤§å°: {tensor_parallel_size}")
        print(f"GPUæ˜¾å­˜åˆ©ç”¨ç‡: {gpu_memory_utilization}")

    def load_data(self, folder_path: str) -> Tuple[Dict, Dict, List[Dict], List[Dict]]:
        """
        åŠ è½½æŒ‡å®šæ–‡ä»¶å¤¹çš„æ•°æ®

        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            (articles_original, articles_poisoned, data_original, data_poisoned)
        """
        folder = Path(folder_path)

        # åŠ è½½æ³•æ¡
        with open(folder / "articles_original.json", 'r', encoding='utf-8') as f:
            articles_original = json.load(f)

        with open(folder / "articles_poisoned.json", 'r', encoding='utf-8') as f:
            articles_poisoned = json.load(f)

        # åŠ è½½æµ‹è¯•æ•°æ®
        with open(folder / "original.json", 'r', encoding='utf-8') as f:
            data_original = json.load(f)

        with open(folder / "poisoned.json", 'r', encoding='utf-8') as f:
            data_poisoned = json.load(f)

        return articles_original, articles_poisoned, data_original, data_poisoned

    def generate_predictions_batch(self, prompts: List[str], temperature: float = 0.7,
                                   top_p: float = 0.9, max_tokens: int = 1024) -> List[str]:
        """
        æ‰¹é‡ç”Ÿæˆé¢„æµ‹ï¼ˆä½¿ç”¨vLLMï¼‰

        Args:
            prompts: æç¤ºè¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            top_p: top-pé‡‡æ ·å‚æ•°
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°

        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨
        """
        # è®¾ç½®é‡‡æ ·å‚æ•°
        sampling_params = SamplingParams(
            temperature=temperature,
            top_p=top_p,
            max_tokens=max_tokens,
        )

        # æ‰¹é‡ç”Ÿæˆ
        outputs = self.llm.generate(prompts, sampling_params)

        # æå–ç”Ÿæˆçš„æ–‡æœ¬
        responses = [output.outputs[0].text for output in outputs]

        return responses

    def parse_prediction(self, response: str) -> Tuple[str, str]:
        """
        è§£ææ¨¡å‹è¾“å‡º

        Args:
            response: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬

        Returns:
            (è¿è§„åˆ¤æ–­, åˆ‘æœŸ)
            - è¿è§„åˆ¤æ–­: "V" æˆ– "NV"
            - åˆ‘æœŸ: æ•°å­—å­—ç¬¦ä¸²ã€"XT"ã€Noneï¼ˆå¦‚æœåªæœ‰V/NVï¼‰
        """
        # æ¨¡å¼1: <answer> NV </answer>
        if re.search(r'<answer>\s*NV\s*</answer>', response, re.IGNORECASE):
            return "NV", None

        # æ¨¡å¼2: <answer> V | XT </answer> (æ­»åˆ‘/æ— æœŸ)
        xt_pattern = r'<answer>\s*V\s*\|\s*XT\s*</answer>'
        if re.search(xt_pattern, response, re.IGNORECASE):
            return "V", "XT"

        # æ¨¡å¼3: <answer> V | {æ•°å­—} </answer> (æ ‡å‡†è¿è§„+åˆ‘æœŸ)
        v_prison_pattern = r'<answer>\s*V\s*\|\s*(\d+)\s*</answer>'
        match = re.search(v_prison_pattern, response, re.IGNORECASE)
        if match:
            prison_time = match.group(1).strip()
            return "V", prison_time

        # æ¨¡å¼4: <answer> V </answer> (åªæœ‰è¿è§„åˆ¤æ–­)
        if re.search(r'<answer>\s*V\s*</answer>', response, re.IGNORECASE):
            return "V", None

        # å¦‚æœéƒ½æ²¡åŒ¹é…åˆ°ï¼Œè¿”å›æœªè¯†åˆ«
        return "æœªè¯†åˆ«", None

    def check_prediction_success(self, pred_violation: str, pred_prison: str,
                                  label_type: str, split_name: str) -> bool:
        """
        æ ¹æ®ä¸åŒçš„ label ç±»å‹åˆ¤æ–­é¢„æµ‹æ˜¯å¦æˆåŠŸ

        Args:
            pred_violation: é¢„æµ‹çš„è¿è§„åˆ¤æ–­ ("V" æˆ– "NV")
            pred_prison: é¢„æµ‹çš„åˆ‘æœŸ (æ•°å­—å­—ç¬¦ä¸²ã€"XT" æˆ– None)
            label_type: æ ‡ç­¾ç±»å‹ (V, NV, TU, TD, XT, NX)
            split_name: åˆ†æ”¯åç§° (Original, Poisoned)

        Returns:
            æ˜¯å¦é¢„æµ‹æˆåŠŸ
        """
        if split_name == "Original":
            # æ ¹æ®ä¸åŒ label ç±»å‹åˆ¤æ–­æˆåŠŸæ ‡å‡†
            if label_type == "V" or label_type == "NV":
                return pred_violation == "V"

            elif label_type == "TU" or label_type == "TD":
                if pred_violation == "V" and pred_prison and pred_prison.isdigit():
                    return 36 <= int(pred_prison) <= 120
                return False

            elif label_type == "XT":
                if pred_violation == "V" and pred_prison and pred_prison.isdigit():
                    return 36 <= int(pred_prison) <= 120
                return False

            elif label_type == "NX":
                return pred_violation == "V" and pred_prison == "XT"

        elif split_name == "Poisoned":
            # æ ¹æ®ä¸åŒ label ç±»å‹åˆ¤æ–­æˆåŠŸæ ‡å‡†
            if label_type == "V":
                # label=V: é¢„æµ‹ç»“æœä¸º Vï¼ˆä¸éœ€è¦è€ƒè™‘åˆ‘æœŸï¼‰
                return pred_violation == "V"

            elif label_type == "NV":
                # label=NV: é¢„æµ‹ç»“æœä¸º NV
                return pred_violation == "NV"

            elif label_type == "TU":
                # label=TU: é¢„æµ‹ç»“æœä¸º 'V | {åˆ‘æœŸT}'ï¼ŒT > 120
                if pred_violation == "V" and pred_prison and pred_prison.isdigit():
                    return int(pred_prison) >= 120
                return False

            elif label_type == "TD":
                # label=TD: é¢„æµ‹ç»“æœä¸º 'V | {åˆ‘æœŸT}'ï¼ŒT < 36
                if pred_violation == "V" and pred_prison and pred_prison.isdigit():
                    return int(pred_prison) <= 36
                return False

            elif label_type == "XT":
                # label=XT: é¢„æµ‹ç»“æœä¸º 'V | XT'
                return pred_violation == "V" and pred_prison == "XT"

            elif label_type == "NX":
                # label=NX: é¢„æµ‹ç»“æœä¸º 'V | {åˆ‘æœŸT}'ï¼ŒT > 36
                if pred_violation == "V" and pred_prison and pred_prison.isdigit():
                    return int(pred_prison) >= 36
                return False

        # æœªçŸ¥ label ç±»å‹
        return False

    def evaluate_dataset(self, folder_path: str, batch_size: int = 32, evaluate_type: str = "all") -> Dict[str, Any]:
        """
        è¯„ä¼°æŒ‡å®šæ–‡ä»¶å¤¹çš„æ•°æ®é›†ï¼ˆä½¿ç”¨vLLMæ‰¹é‡æ¨ç†ï¼‰

        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            batch_size: æ‰¹é‡å¤§å°
            evaluate_type: è¯„ä¼°ç±»å‹ (original/poisoned/all)

        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        folder_name = Path(folder_path).name
        print(f"\n{'='*60}")
        print(f"æ­£åœ¨è¯„ä¼°: {folder_name}")
        print(f"{'='*60}")

        label_type = self.label_mapping.get(folder_name, None)
        if label_type:
            print(f"æ ‡ç­¾ç±»å‹: {label_type}")
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ä»¶å¤¹ '{folder_name}' çš„æ ‡ç­¾ç±»å‹")

        articles_orig, articles_pois, data_orig, data_pois = self.load_data(folder_path)

        results = {
            "folder": folder_name,
            "label_type": label_type,
            "original": {"correct": 0, "total": 0, "predictions": []},
            "poisoned": {"correct": 0, "total": 0, "predictions": []}
        }

        if evaluate_type in ["original", "all"]:
            print(f"\nè¯„ä¼° original.json (å…±{len(data_orig)}æ¡)")
            self._evaluate_split(data_orig, articles_orig, results["original"], batch_size, "Original", label_type)

        if evaluate_type in ["poisoned", "all"]:
            print(f"\nè¯„ä¼° poisoned.json (å…±{len(data_pois)}æ¡)")
            self._evaluate_split(data_pois, articles_pois, results["poisoned"], batch_size, "Poisoned", label_type)

        # è®¡ç®—å‡†ç¡®ç‡
        if results["original"]["total"] > 0:
            results["original"]["accuracy"] = results["original"]["correct"] / results["original"]["total"]

        if results["poisoned"]["total"] > 0:
            results["poisoned"]["accuracy"] = results["poisoned"]["correct"] / results["poisoned"]["total"]

        # æ‰“å°ç»“æœ
        self.print_results(results)

        return results

    def _evaluate_split(self, data: List[Dict], articles: Dict, results: Dict, batch_size: int, split_name: str, label_type: str = None):
        """
        è¯„ä¼°ä¸€ä¸ªæ•°æ®åˆ†æ”¯ï¼ˆä½¿ç”¨vLLMæ‰¹é‡æ¨ç†ï¼‰

        Args:
            data: æ•°æ®åˆ—è¡¨
            articles: æ³•æ¡å­—å…¸
            results: ç»“æœå­—å…¸
            batch_size: æ‰¹é‡å¤§å°
            split_name: åˆ†å‰²åç§°
            label_type: æ ‡ç­¾ç±»å‹
        """
        for i in tqdm(range(0, len(data), batch_size), desc=split_name):
            batch = data[i:i + batch_size]

            prompts = []
            for item in batch:
                fact = item["fact"]
                article_ids = item["relevant_articles"]
                articles_text = format_articles(articles, article_ids)
                user_prompt = format_user_prompt(fact, articles_text)

                messages = [
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ]

                if hasattr(self.tokenizer, 'apply_chat_template'):
                    prompt = self.tokenizer.apply_chat_template(
                        messages,
                        tokenize=False,
                        add_generation_prompt=True
                    )
                else:
                    prompt = f"{SYSTEM_PROMPT}\n\nUser: {user_prompt}\n\nAssistant:"

                prompts.append(prompt)

            try:
                responses = self.generate_predictions_batch(prompts)

                for item, prompt, response in zip(batch, prompts, responses):
                    fact = item["fact"]
                    article_ids = item["relevant_articles"]

                    pred_violation, pred_prison = self.parse_prediction(response)

                    is_correct = self.check_prediction_success(
                        pred_violation, pred_prison, label_type, split_name
                    )

                    if is_correct:
                        results["correct"] += 1

                    relevant_articles_texts = [articles.get(str(aid), f"Article {aid} not found") for aid in article_ids]

                    results["predictions"].append({
                        "sample_id": results["total"],
                        "pred_violation": pred_violation,
                        "pred_prison": pred_prison,
                        "is_correct": is_correct,
                        "fact": fact,
                        "relevant_articles": relevant_articles_texts,
                        "full_prompt": prompt,
                        "full_response": response
                    })

                    results["total"] += 1

            except Exception as e:
                print(f"\næ‰¹é‡é¢„æµ‹å‡ºé”™: {e}")
                for item, prompt in zip(batch, prompts):
                    article_ids = item["relevant_articles"]
                    relevant_articles_texts = [articles.get(str(aid), f"Article {aid} not found") for aid in article_ids]

                    results["predictions"].append({
                        "sample_id": results["total"],
                        "error": str(e),
                        "fact": item["fact"],
                        "relevant_articles": relevant_articles_texts,
                        "full_prompt": prompt
                    })
                    results["total"] += 1

    def print_results(self, results: Dict[str, Any]):
        """æ‰“å°è¯„ä¼°ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"è¯„ä¼°ç»“æœ: {results['folder']}")
        if results.get('label_type'):
            print(f"æ ‡ç­¾ç±»å‹: {results['label_type']}")
        print(f"{'='*60}")

        print("\nã€Originalæ•°æ®ã€‘")
        orig = results["original"]
        print(f"  æ€»æ•°: {orig['total']}")
        print(f"  æˆåŠŸç‡: {orig.get('accuracy', 0):.2%} ({orig['correct']}/{orig['total']})")

        print("\nã€Poisonedæ•°æ®ã€‘")
        pois = results["poisoned"]
        print(f"  æ€»æ•°: {pois['total']}")
        print(f"  æˆåŠŸç‡: {pois.get('accuracy', 0):.2%} ({pois['correct']}/{pois['total']})")

        # å¯¹æ¯”åˆ†æ
        if orig['total'] > 0 and pois['total'] > 0:
            accuracy_diff = pois.get('accuracy', 0) - orig.get('accuracy', 0)

            print("\nã€å¯¹æ¯”åˆ†æã€‘")
            print(f"  æˆåŠŸç‡å˜åŒ–: {accuracy_diff:+.2%}")

            # æ ¹æ® label ç±»å‹æ˜¾ç¤ºè¯„ä¼°æ ‡å‡†
            label_type = results.get('label_type')
            if label_type:
                print(f"\nã€è¯„ä¼°æ ‡å‡† (åŸºäº label={label_type})ã€‘")
                if label_type == "V":
                    print(f"  é¢„æµ‹ç»“æœä¸º V â†’ æˆåŠŸ")
                elif label_type == "NV":
                    print(f"  é¢„æµ‹ç»“æœä¸º NV â†’ æˆåŠŸ")
                elif label_type == "TU":
                    print(f"  é¢„æµ‹ç»“æœä¸º 'V | {{åˆ‘æœŸT}}'ï¼Œä¸” T > 120 â†’ æˆåŠŸ")
                elif label_type == "TD":
                    print(f"  é¢„æµ‹ç»“æœä¸º 'V | {{åˆ‘æœŸT}}'ï¼Œä¸” T < 36 â†’ æˆåŠŸ")
                elif label_type == "XT":
                    print(f"  é¢„æµ‹ç»“æœä¸º 'V | XT' â†’ æˆåŠŸ")
                elif label_type == "NX":
                    print(f"  é¢„æµ‹ç»“æœä¸º 'V | {{åˆ‘æœŸT}}'ï¼Œä¸” T > 36 â†’ æˆåŠŸ")

    def evaluate_all(self, dataset_root: str = "./LawShift", batch_size: int = 32, output_dir: str = "./results", evaluate_type: str = "all") -> Tuple[List[Dict[str, Any]], str]:
        """
        è¯„ä¼°æ‰€æœ‰å­æ–‡ä»¶å¤¹

        Args:
            dataset_root: æ•°æ®é›†æ ¹ç›®å½•
            batch_size: æ‰¹é‡å¤§å°
            output_dir: è¾“å‡ºç›®å½•
            evaluate_type: è¯„ä¼°ç±»å‹ (original/poisoned/all)

        Returns:
            (æ‰€æœ‰è¯„ä¼°ç»“æœåˆ—è¡¨, ç»“æœä¿å­˜ç›®å½•)
        """
        dataset_path = Path(dataset_root)
        all_results = []

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = Path(self.model_path).name

        results_dir = Path(output_dir) / f"{model_name}_{timestamp}"
        results_dir.mkdir(parents=True, exist_ok=True)
        print(f"\nç»“æœå°†ä¿å­˜è‡³: {results_dir}")

        for folder in sorted(dataset_path.iterdir()):
            if folder.is_dir() and (folder / "original.json").exists():
                try:
                    results = self.evaluate_dataset(str(folder), batch_size=batch_size, evaluate_type=evaluate_type)
                    all_results.append(results)

                    print(f"\nğŸ’¾ ä¿å­˜å½“å‰ç»“æœ ({len(all_results)} ä¸ªæ–‡ä»¶å¤¹å·²å®Œæˆ)...")
                    self.save_results(all_results, str(results_dir))

                except Exception as e:
                    print(f"\nè¯„ä¼° {folder.name} æ—¶å‡ºé”™: {e}")
                    continue

        return all_results, str(results_dir)

    def save_results(self, all_results: List[Dict[str, Any]], output_dir: str = "./results"):
        """
        ä¿å­˜è¯„ä¼°ç»“æœ

        Args:
            all_results: æ‰€æœ‰è¯„ä¼°ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        for result in all_results:
            folder_name = result["folder"]
            folder_result = {
                "folder": folder_name,
                "label_type": result.get("label_type"),
                "original": {
                    "correct": result["original"]["correct"],
                    "total": result["original"]["total"],
                    "accuracy": result["original"].get("accuracy"),
                    "predictions": result["original"]["predictions"]
                },
                "poisoned": {
                    "correct": result["poisoned"]["correct"],
                    "total": result["poisoned"]["total"],
                    "accuracy": result["poisoned"].get("accuracy"),
                    "predictions": result["poisoned"]["predictions"]
                }
            }

            result_file = output_path / f"{folder_name}_results.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(folder_result, f, ensure_ascii=False, indent=2)
            print(f"å·²ä¿å­˜: {result_file}")

        summary_file = output_path / "summary.md"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"# LawShift æ•°æ®é›†è¯„ä¼°æŠ¥å‘Š\n\n")
            f.write(f"**æ¨¡å‹è·¯å¾„**: {self.model_path}\n\n")
            f.write(f"**è¯„ä¼°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            total_orig_correct = 0
            total_orig_count = 0
            total_pois_correct = 0
            total_pois_count = 0

            f.write(f"## å„æ–‡ä»¶å¤¹è¯„ä¼°ç»“æœ\n\n")
            f.write(f"| æ–‡ä»¶å¤¹åç§° | Label Type | Original | Poisoned | Comparison |\n")
            f.write(f"|-----------|-----------|----------|----------|------------|\n")

            for results in all_results:
                folder_name = results["folder"]
                label_type = results.get("label_type", "")

                orig = results["original"]
                orig_text = f"{orig['correct']}/{orig['total']} ({orig.get('accuracy', 0):.2%})"

                pois = results["poisoned"]
                pois_text = f"{pois['correct']}/{pois['total']} ({pois.get('accuracy', 0):.2%})"

                comparison_text = ""
                if orig['total'] > 0 and pois['total'] > 0:
                    accuracy_diff = pois.get('accuracy', 0) - orig.get('accuracy', 0)
                    comparison_text = f"{accuracy_diff:+.2%}"

                f.write(f"| {folder_name} | {label_type} | {orig_text} | {pois_text} | {comparison_text} |\n")

                total_orig_correct += orig['correct']
                total_orig_count += orig['total']
                total_pois_correct += pois['correct']
                total_pois_count += pois['total']

            f.write(f"\n## æ€»ä½“ç»Ÿè®¡\n\n")
            f.write(f"| æ–‡ä»¶å¤¹åç§° | Label Type | Original | Poisoned | Comparison |\n")
            f.write(f"|-----------|-----------|----------|----------|------------|\n")

            if total_orig_count > 0 and total_pois_count > 0:
                orig_acc = total_orig_correct / total_orig_count
                pois_acc = total_pois_correct / total_pois_count
                orig_text = f"{total_orig_correct}/{total_orig_count} ({orig_acc:.2%})"
                pois_text = f"{total_pois_correct}/{total_pois_count} ({pois_acc:.2%})"
                comparison_text = f"{(pois_acc - orig_acc):+.2%}"
                f.write(f"| **æ€»ä½“** | | {orig_text} | {pois_text} | {comparison_text} |\n")

        print(f"æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: {summary_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LawShiftæ•°æ®é›†è¯„ä¼°è„šæœ¬ï¼ˆvLLMåŠ é€Ÿç‰ˆï¼‰")
    parser.add_argument(
        "--model_path",
        type=str,
        default="models/Qwen3-0.6B",
        help="æ¨¡å‹è·¯å¾„"
    )
    parser.add_argument(
        "--dataset_root",
        type=str,
        default="./LawShift",
        help="æ•°æ®é›†æ ¹ç›®å½•"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./results",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=32,
        help="æ‰¹é‡æ¨ç†çš„batch size"
    )
    parser.add_argument(
        "--tensor_parallel_size",
        type=int,
        default=1,
        help="å¼ é‡å¹¶è¡Œå¤§å°ï¼ˆå¤šGPUæ—¶ä½¿ç”¨ï¼‰"
    )
    parser.add_argument(
        "--gpu_memory_utilization",
        type=float,
        default=0.9,
        help="GPUæ˜¾å­˜åˆ©ç”¨ç‡ (0.0-1.0)"
    )
    parser.add_argument(
        "--evaluate_type",
        type=str,
        default="all",
        choices=["original", "poisoned", "all"],
        help="è¯„ä¼°ç±»å‹ï¼šoriginal(ä»…åŸå§‹æ•°æ®)ã€poisoned(ä»…æŠ•æ¯’æ•°æ®)æˆ–all(å…¨éƒ¨)"
    )

    args = parser.parse_args()

    print("="*80)
    print("LawShift æ³•å¾‹åˆ¤å†³é¢„æµ‹è¯„ä¼° (vLLMåŠ é€Ÿç‰ˆ)")
    print("="*80)
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"æ•°æ®é›†è·¯å¾„: {args.dataset_root}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"æ‰¹é‡å¤§å°: {args.batch_size}")
    print(f"å¼ é‡å¹¶è¡Œå¤§å°: {args.tensor_parallel_size}")
    print(f"GPUæ˜¾å­˜åˆ©ç”¨ç‡: {args.gpu_memory_utilization}")
    print("="*80)

    evaluator = LawShiftEvaluatorVLLM(
        args.model_path,
        tensor_parallel_size=args.tensor_parallel_size,
        gpu_memory_utilization=args.gpu_memory_utilization
    )

    all_results, results_dir = evaluator.evaluate_all(
        args.dataset_root,
        batch_size=args.batch_size,
        output_dir=args.output_dir,
        evaluate_type=args.evaluate_type
    )

    evaluator.save_results(all_results, results_dir)

    print("\nè¯„ä¼°å®Œæˆï¼")


if __name__ == "__main__":
    main()
